{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font settings\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Enhanced font size configuration\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 26\n",
    "\n",
    "print(\"Font settings configured for enhanced readability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = r\"F:\\作图目录20280825\\骨质疏松数据.xlsx\"\n",
    "df = pd.read_excel(data_file, header=1, usecols='B:H') \n",
    "cols = ['signal_1', 'sost_1', 'signal_2', 'sost_2', 'sost_mean', 'l1_4', 'left_hip']\n",
    "df.columns = cols\n",
    "\n",
    "print(f\"Data dimensions: {df.shape}\")\n",
    "print(f\"Features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class labels\n",
    "if len(df) == 103:\n",
    "    df['class'] = ['Healthy'] * 35 + ['Osteopenia'] * 33 + ['Osteoporosis'] * 35\n",
    "else:\n",
    "    df['class'] = ['Healthy'] * 35 + ['Osteopenia'] * 33 + ['Osteoporosis'] * 36\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "y = df['class'].map({'Healthy': 0, 'Osteopenia': 1, 'Osteoporosis': 2})\n",
    "print(f\"\\nLabel mapping: {dict(zip(['Healthy', 'Osteopenia', 'Osteoporosis'], [0, 1, 2]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_configs = {\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True, random_state=42),\n",
    "        'params': {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']},\n",
    "        'needs_scaling': True,\n",
    "        'color': '#24AAE3'\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [50, 100], 'max_depth': [None, 5, 10]},\n",
    "        'needs_scaling': False,\n",
    "        'color': '#E9C581'\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {'C': [0.1, 1, 10]},\n",
    "        'needs_scaling': True,\n",
    "        'color': '#CABBDB'\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [3, 5, 7]},\n",
    "        'needs_scaling': True,\n",
    "        'color': '#95B9B9'\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {'max_depth': [None, 5, 10]},\n",
    "        'needs_scaling': False,\n",
    "        'color': '#FDC1C1'\n",
    "    },\n",
    "    'Linear Discriminant Analysis': {\n",
    "        'model': LinearDiscriminantAnalysis(),\n",
    "        'params': {},\n",
    "        'needs_scaling': False,\n",
    "        'color': '#7D9A18'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algorithm(algo_name, config, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train algorithm and return prediction probabilities\"\"\"\n",
    "    print(f\"Training: {algo_name}...\")\n",
    "    \n",
    "    # Data standardization\n",
    "    if config['needs_scaling']:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled = X_train\n",
    "        X_test_scaled = X_test\n",
    "    \n",
    "    # Parameter optimization\n",
    "    if config['params']:\n",
    "        grid_search = GridSearchCV(config['model'], config['params'], cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"  ✓ Best parameters: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        best_model = config['model']\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        print(\"  ✓ Using default parameters\")\n",
    "    \n",
    "    # Prediction probabilities\n",
    "    try:\n",
    "        y_proba = best_model.predict_proba(X_test_scaled)\n",
    "        return y_proba\n",
    "    except:\n",
    "        print(f\"  ⚠ {algo_name} cannot generate probability predictions\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves_enhanced(y_true, y_proba_dict, title, feature_name, save_path=None):\n",
    "    \"\"\"Plot enhanced ROC curves\"\"\"\n",
    "    \n",
    "    y_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
    "    n_classes = y_bin.shape[1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 11))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for algo_name, y_proba in y_proba_dict.items():\n",
    "        if y_proba is None:\n",
    "            continue\n",
    "            \n",
    "        # Calculate ROC curves\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_proba[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Calculate macro-average ROC\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_tpr /= n_classes\n",
    "        \n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "        \n",
    "        # Get color\n",
    "        color = next((config['color'] for name, config in algo_configs.items() \n",
    "                     if name == algo_name), '#0066CC')\n",
    "        \n",
    "        # Plot macro-average ROC curve\n",
    "        line_width = 4 if algo_name == 'SVM' else 3\n",
    "        ax.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                label=f'{algo_name} (AUC = {roc_auc[\"macro\"]:.3f})',\n",
    "                color=color, linestyle='-', linewidth=line_width, alpha=0.9)\n",
    "        \n",
    "        results.append({\n",
    "            'algorithm': algo_name,\n",
    "            'auc': roc_auc[\"macro\"],\n",
    "            'color': color\n",
    "        })\n",
    "    \n",
    "    # Diagonal reference line\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=2.5, alpha=0.8, label='Random Classifier')\n",
    "    \n",
    "    ax.set_xlim([-0.02, 1.02])\n",
    "    ax.set_ylim([-0.02, 1.02])\n",
    "    \n",
    "    ax.set_xlabel('False Positive Rate', fontsize=22, fontweight='bold', labelpad=15)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=22, fontweight='bold', labelpad=15)\n",
    "    ax.set_title(title, fontsize=26, fontweight='bold', pad=30)\n",
    "    \n",
    "    ax.set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18, length=8, width=2)\n",
    "    \n",
    "    legend = ax.legend(loc=\"lower right\", fontsize=16, frameon=True, \n",
    "                       fancybox=True, shadow=True, framealpha=0.95,\n",
    "                       edgecolor='black', facecolor='white',\n",
    "                       borderpad=1.2, labelspacing=1.5)\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "    \n",
    "    ax.set_facecolor('white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(3)\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(f\"{save_path}_high_res.tiff\", dpi=600, bbox_inches='tight', \n",
    "                    facecolor='white', format='tiff')\n",
    "        plt.savefig(f\"{save_path}_vector.pdf\", format='pdf', bbox_inches='tight', \n",
    "                    facecolor='white')\n",
    "        print(f\"✓ Saved: {save_path}_high_res.tiff and {save_path}_vector.pdf\")\n",
    "    \n",
    "    plt.show()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOST1 + SOST2 Six-Algorithm ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Generating SOST1 + SOST2 6-algorithm ROC curves ===\")\n",
    "\n",
    "X_sost = df[['sost_1', 'sost_2']].values\n",
    "X_sost_train, X_sost_test, y_sost_train, y_sost_test = train_test_split(\n",
    "    X_sost, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Train all algorithms\n",
    "y_proba_sost_dict = {}\n",
    "for algo_name, config in algo_configs.items():\n",
    "    y_proba = train_algorithm(algo_name, config, X_sost_train, X_sost_test, \n",
    "                             y_sost_train, y_sost_test)\n",
    "    if y_proba is not None:\n",
    "        y_proba_sost_dict[algo_name] = y_proba\n",
    "\n",
    "# Generate ROC curves\n",
    "output_dir = r\"F:\\作图目录20280825\\ROC_curves_enhanced\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path_sost = os.path.join(output_dir, \"ROC_SOST1_SOST2_6algorithms\")\n",
    "results_sost = plot_roc_curves_enhanced(\n",
    "    y_sost_test, y_proba_sost_dict, \n",
    "    'SOST1 + SOST2 Features', \n",
    "    'SOST1+SOST2', \n",
    "    save_path_sost\n",
    ")\n",
    "\n",
    "print(\"\\n=== SOST1+SOST2 6-algorithms completed ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal1 + Signal2 Six-Algorithm ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Generating Signal1 + Signal2 6-algorithm ROC curves ===\")\n",
    "\n",
    "X_signal = df[['signal_1', 'signal_2']].values\n",
    "X_signal_train, X_signal_test, y_signal_train, y_signal_test = train_test_split(\n",
    "    X_signal, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Train all algorithms\n",
    "y_proba_signal_dict = {}\n",
    "for algo_name, config in algo_configs.items():\n",
    "    y_proba = train_algorithm(algo_name, config, X_signal_train, X_signal_test, \n",
    "                             y_signal_train, y_signal_test)\n",
    "    if y_proba is not None:\n",
    "        y_proba_signal_dict[algo_name] = y_proba\n",
    "\n",
    "# Generate ROC curves\n",
    "save_path_signal = os.path.join(output_dir, \"ROC_Signal1_Signal2_6algorithms\")\n",
    "results_signal = plot_roc_curves_enhanced(\n",
    "    y_signal_test, y_proba_signal_dict, \n",
    "    'Signal1 + Signal2 Features', \n",
    "    'Signal1+Signal2', \n",
    "    save_path_signal\n",
    ")\n",
    "\n",
    "print(\"\\n=== Signal1+Signal2 6-algorithms completed ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary table\n",
    "summary_data = []\n",
    "\n",
    "if 'results_sost' in locals():\n",
    "    for result in results_sost:\n",
    "        summary_data.append({\n",
    "            'Feature Combination': 'SOST1+SOST2',\n",
    "            'Algorithm': result['algorithm'],\n",
    "            'AUC Score': f\"{result['auc']:.3f}\",\n",
    "            'Rank': ''\n",
    "        })\n",
    "\n",
    "if 'results_signal' in locals():\n",
    "    for result in results_signal:\n",
    "        summary_data.append({\n",
    "            'Feature Combination': 'Signal1+Signal2',\n",
    "            'Algorithm': result['algorithm'],\n",
    "            'AUC Score': f\"{result['auc']:.3f}\",\n",
    "            'Rank': ''\n",
    "        })\n",
    "\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Add ranking\n",
    "    summary_df['AUC_Numeric'] = summary_df['AUC Score'].astype(float)\n",
    "    summary_df = summary_df.sort_values(['Feature Combination', 'AUC_Numeric'], ascending=[True, False])\n",
    "    \n",
    "    # Group ranking by feature combination\n",
    "    summary_df['Rank'] = summary_df.groupby('Feature Combination')['AUC_Numeric'].rank(ascending=False, method='min').astype(int)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"=== Algorithm Performance Summary ===\")\n",
    "    print(summary_df[['Feature Combination', 'Algorithm', 'AUC Score', 'Rank']].to_string(index=False))\n",
    "    \n",
    "    # Save results\n",
    "    summary_file = os.path.join(output_dir, \"Algorithm_Performance_Summary.xlsx\")\n",
    "    summary_df[['Feature Combination', 'Algorithm', 'AUC Score', 'Rank']].to_excel(summary_file, index=False)\n",
    "    print(f\"\\n✓ Results saved to: {summary_file}\")\n",
    "else:\n",
    "    print(\"⚠ No results data available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
