{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_recall_fscore_support, \n",
    "                           classification_report, roc_auc_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置字体 - 使用 Arial\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"开始Signal1+Signal2特征分类性能分析...\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 数据加载和预处理 ==========\n",
    "print(\"\\n>>> 加载骨质疏松数据...\")\n",
    "data_file = r\"F:\\作图目录20280825\\骨质疏松数据.xlsx\"\n",
    "df = pd.read_excel(data_file, header=1, usecols='B:H') \n",
    "cols = ['signal_1', 'sost_1', 'signal_2', 'sost_2', 'sost_mean', 'l1_4', 'left_hip']\n",
    "df.columns = cols\n",
    "\n",
    "print(f\"数据维度: {df.shape}\")\n",
    "\n",
    "# 添加类别标签\n",
    "if len(df) == 103:\n",
    "    df['class'] = ['Health'] * 35 + ['Osteopenia'] * 33 + ['Osteoporosis'] * 35\n",
    "    print(\"103行数据，分配: Health(35) + Osteopenia(33) + Osteoporosis(35)\")\n",
    "else:\n",
    "    df['class'] = ['Health'] * 35 + ['Osteopenia'] * 33 + ['Osteoporosis'] * 36\n",
    "    print(\"104行数据，分配: Health(35) + Osteopenia(33) + Osteoporosis(36)\")\n",
    "\n",
    "print(\"类别分布:\")\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# 准备特征数据 - 仅使用signal_1和signal_2\n",
    "X = df[['signal_1', 'signal_2']].values\n",
    "y = df['class'].map({'Health': 0, 'Osteopenia': 1, 'Osteoporosis': 2})\n",
    "\n",
    "print(f\"\\n特征维度: {X.shape}\")\n",
    "print(\"特征名称: Signal1(COL.), Signal2(FL.)\")\n",
    "print(\"目标变量分布:\", y.value_counts().sort_index())\n",
    "\n",
    "# 分割数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "print(f\"训练集大小: {X_train.shape[0]}, 测试集大小: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 淘宝代码风格配置 ==========\n",
    "print(\"\\n>>> 设置淘宝代码风格的颜色方案...\")\n",
    "\n",
    "# 颜色配置 - 保持与淘宝代码一致\n",
    "COLORS = {\n",
    "    \"green_light\": \"#C9DCC4\",\n",
    "    \"green_transparent\": \"#94C3AA\",\n",
    "    \"blue_light\": \"#D7E8F3\",\n",
    "    \"blue_transparent\": \"#8ec1dc\",\n",
    "    \"teal_transparent\": \"#57B1AB\",\n",
    "    \"new\": \"#DF9D96\"\n",
    "}\n",
    "\n",
    "# 创建颜色映射\n",
    "train_cmap = LinearSegmentedColormap.from_list(\"train_cmap\", [COLORS[\"blue_light\"], COLORS[\"blue_transparent\"]], N=256)\n",
    "test_cmap = LinearSegmentedColormap.from_list(\"test_cmap\", [COLORS[\"green_light\"], COLORS[\"green_transparent\"]], N=256)\n",
    "\n",
    "print(\"✅ 颜色方案配置完成\")\n",
    "\n",
    "# 算法配置 - 保持与原文档一致\n",
    "algo_configs = {\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True, random_state=42),\n",
    "        'params': {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']},\n",
    "        'needs_scaling': True,\n",
    "        'color': '#57B1AB'\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [50, 100], 'max_depth': [None, 5, 10]},\n",
    "        'needs_scaling': False,\n",
    "        'color': '#94C3AA'\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {'C': [0.1, 1, 10]},\n",
    "        'needs_scaling': True,\n",
    "        'color': '#8ec1dc'\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [3, 5, 7]},\n",
    "        'needs_scaling': True,\n",
    "        'color': '#DF9D96'\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {'max_depth': [None, 5, 10]},\n",
    "        'needs_scaling': False,\n",
    "        'color': '#C9DCC4'\n",
    "    },\n",
    "    'LDA': {\n",
    "        'model': LinearDiscriminantAnalysis(),\n",
    "        'params': {},\n",
    "        'needs_scaling': False,\n",
    "        'color': '#8ec1dc'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ 算法配置完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵绘制函数 - 再次增大矩阵内数字，确保绝对清晰可读\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title, cmap, save_path_base=None):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵热图，保存为TIFF和PDF格式，矩阵内数字再次增大\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "    \n",
    "    # 保持8x7图片尺寸，但增大矩阵内数字\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='g', cmap=cmap, \n",
    "                     xticklabels=labels, yticklabels=labels, \n",
    "                     cbar=False, annot_kws={\"size\": 28, \"color\": \"black\", \"weight\": \"bold\"}, \n",
    "                     linewidths=1.5, square=True)\n",
    "    \n",
    "    # 标题保持18号字体\n",
    "    ax.set_title(title, fontsize=18, fontweight='bold', pad=30)\n",
    "    \n",
    "    # 坐标轴标签保持18号\n",
    "    ax.set_xlabel('Predicted', fontsize=18, fontweight='bold', labelpad=20)\n",
    "    ax.set_ylabel('Actual', fontsize=18, fontweight='bold', labelpad=20)\n",
    "    \n",
    "    # 刻度标签保持16号\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center', fontsize=16, \n",
    "                       verticalalignment='top')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=90, ha='center', fontsize=16,\n",
    "                       verticalalignment='center')\n",
    "    \n",
    "    # 保持间距设置\n",
    "    ax.tick_params(axis='x', pad=15, length=6)\n",
    "    ax.tick_params(axis='y', pad=12, length=6)\n",
    "    \n",
    "    # 确保正方形热图区域\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.subplots_adjust(bottom=0.22, top=0.85, left=0.22, right=0.95)\n",
    "    \n",
    "    if save_path_base:\n",
    "        # 保存为TIFF格式\n",
    "        tiff_path = f\"{save_path_base}.tiff\"\n",
    "        plt.savefig(tiff_path, format='tiff', dpi=300, bbox_inches='tight', \n",
    "                    facecolor='white', pad_inches=0.3)\n",
    "        \n",
    "        # 保存为PDF格式\n",
    "        pdf_path = f\"{save_path_base}.pdf\"\n",
    "        plt.savefig(pdf_path, format='pdf', bbox_inches='tight', \n",
    "                    facecolor='white', pad_inches=0.3)\n",
    "        \n",
    "        print(f\"  ✅ 保存: {os.path.basename(tiff_path)}, {os.path.basename(pdf_path)}\")\n",
    "        plt.close()\n",
    "        return tiff_path, pdf_path\n",
    "    else:\n",
    "        plt.show()\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_comprehensive_metrics(y_true, y_pred, y_proba=None):\n",
    "    \"\"\"计算全面的评估指标\"\"\"\n",
    "    # 基础指标\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # 各类别的精确率、召回率、F1分数\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, \n",
    "                                                                    average=None, zero_division=0)\n",
    "    \n",
    "    # 宏平均和加权平均\n",
    "    prec_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[0]\n",
    "    recall_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[1]\n",
    "    f1_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[2]\n",
    "    \n",
    "    prec_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[0]\n",
    "    recall_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[1]\n",
    "    f1_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[2]\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # AUC分数（如果有概率预测）\n",
    "    auc_score = None\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision_macro': prec_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_weighted': prec_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision_per_class': precision,\n",
    "        'recall_per_class': recall,\n",
    "        'f1_per_class': f1,\n",
    "        'support_per_class': support,\n",
    "        'confusion_matrix': cm,\n",
    "        'auc_score': auc_score,\n",
    "        'classification_report': classification_report(y_true, y_pred, target_names=['Health', 'Osteopenia', 'Osteoporosis'])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algorithm(algo_name, config, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"训练单个算法并返回完整结果\"\"\"\n",
    "    print(f\"\\n--- 训练 {algo_name} ---\")\n",
    "    \n",
    "    # 数据标准化处理\n",
    "    if config['needs_scaling']:\n",
    "        print(f\"  应用z-score标准化...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled = X_train.copy()\n",
    "        X_test_scaled = X_test.copy()\n",
    "        scaler = None\n",
    "    \n",
    "    # 参数优化\n",
    "    model = config['model']\n",
    "    param_grid = config['params']\n",
    "    \n",
    "    if param_grid:\n",
    "        print(f\"  参数优化中...\")\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"  最佳参数: {best_params}\")\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        best_params = \"Default\"\n",
    "        print(\"  使用默认参数\")\n",
    "    \n",
    "    # 预测\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # 概率预测（如果支持）\n",
    "    try:\n",
    "        y_train_proba = best_model.predict_proba(X_train_scaled)\n",
    "        y_test_proba = best_model.predict_proba(X_test_scaled)\n",
    "    except:\n",
    "        y_train_proba = None\n",
    "        y_test_proba = None\n",
    "    \n",
    "    # 计算性能指标\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    train_metrics = compute_comprehensive_metrics(y_train, y_train_pred, y_train_proba)\n",
    "    test_metrics = compute_comprehensive_metrics(y_test, y_test_pred, y_test_proba)\n",
    "    \n",
    "    # 交叉验证\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "    \n",
    "    print(f\"  训练准确率: {train_acc:.4f}\")\n",
    "    print(f\"  测试准确率: {test_acc:.4f}\")\n",
    "    if test_metrics['auc_score']:\n",
    "        print(f\"  测试AUC: {test_metrics['auc_score']:.4f}\")\n",
    "    print(f\"  5折CV: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'algorithm': algo_name,\n",
    "        'model': best_model,\n",
    "        'scaler': scaler,\n",
    "        'best_params': best_params,\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'y_train_proba': y_train_proba,\n",
    "        'y_test_proba': y_test_proba\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 训练所有算法 ==========\n",
    "print(\"\\n>>> 开始训练和评估六个机器学习算法...\")\n",
    "all_results = []\n",
    "class_labels = ['Health', 'Osteopenia', 'Osteoporosis']\n",
    "\n",
    "for algo_name, config in algo_configs.items():\n",
    "    result = train_algorithm(algo_name, config, X_train, X_test, y_train, y_test)\n",
    "    all_results.append(result)\n",
    "\n",
    "print(f\"\\n✅ 所有算法训练完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 生成混淆矩阵热图 ==========\n",
    "print(\"\\n>>> 生成混淆矩阵热图(TIFF和PDF格式)...\")\n",
    "\n",
    "# 创建输出目录\n",
    "output_dir = r\"F:\\作图目录20280825\\signal_confusion_matrices\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "generated_files = []\n",
    "\n",
    "for result in all_results:\n",
    "    algo_name = result['algorithm']\n",
    "    print(f\"\\n生成 {algo_name} 混淆矩阵...\")\n",
    "    \n",
    "    # 训练集混淆矩阵\n",
    "    train_title = f\"Confusion Matrix(Train) - {algo_name}\"\n",
    "    train_path_base = os.path.join(output_dir, f\"{algo_name.replace(' ', '_')}_signal_train\")\n",
    "    tiff_train, pdf_train = plot_confusion_matrix(\n",
    "        result['y_train'], result['y_train_pred'], \n",
    "        class_labels, train_title, train_cmap, train_path_base\n",
    "    )\n",
    "    \n",
    "    # 测试集混淆矩阵\n",
    "    test_title = f\"Confusion Matrix(Test) - {algo_name}\"\n",
    "    test_path_base = os.path.join(output_dir, f\"{algo_name.replace(' ', '_')}_signal_test\")\n",
    "    tiff_test, pdf_test = plot_confusion_matrix(\n",
    "        result['y_test'], result['y_test_pred'], \n",
    "        class_labels, test_title, test_cmap, test_path_base\n",
    "    )\n",
    "    \n",
    "    if tiff_train and pdf_train and tiff_test and pdf_test:\n",
    "        generated_files.extend([tiff_train, pdf_train, tiff_test, pdf_test])\n",
    "\n",
    "print(f\"\\n✅ 共生成 {len(generated_files)} 个混淆矩阵图片文件\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 性能结果汇总 ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Signal1+Signal2特征分类性能汇总\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "performance_data = []\n",
    "for result in all_results:\n",
    "    test_metrics = result['test_metrics']\n",
    "    auc_str = f\"{test_metrics['auc_score']:.4f}\" if test_metrics['auc_score'] else \"N/A\"\n",
    "    performance_data.append({\n",
    "        '算法': result['algorithm'],\n",
    "        '训练准确率': f\"{result['train_accuracy']:.4f}\",\n",
    "        '测试准确率': f\"{result['test_accuracy']:.4f}\", \n",
    "        '精确率(宏平均)': f\"{test_metrics['precision_macro']:.4f}\",\n",
    "        '召回率(宏平均)': f\"{test_metrics['recall_macro']:.4f}\",\n",
    "        'F1分数(宏平均)': f\"{test_metrics['f1_macro']:.4f}\",\n",
    "        'AUC分数': auc_str,\n",
    "        'CV均值': f\"{result['cv_mean']:.4f}\",\n",
    "        'CV标准差': f\"{result['cv_std']:.4f}\"\n",
    "    })\n",
    "\n",
    "perf_df = pd.DataFrame(performance_data)\n",
    "print(perf_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n✅ 分析完成！所有混淆矩阵热图已保存，字体大小已优化避免重叠\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}