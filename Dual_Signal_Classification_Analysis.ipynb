{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
                "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_recall_fscore_support, \n",
                "                           classification_report, roc_auc_score)\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from matplotlib.colors import LinearSegmentedColormap\n",
                "import warnings\n",
                "import os\n",
                "from datetime import datetime\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set font to Arial\n",
                "plt.rcParams['font.sans-serif'] = ['Arial']\n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "\n",
                "print(\"Starting Signal1+Signal2 feature classification analysis...\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n>>> Loading osteoporosis data...\")\n",
                "data_file = r\"F:\\作图目录20280825\\骨质疏松数据.xlsx\"\n",
                "df = pd.read_excel(data_file, header=1, usecols='B:H') \n",
                "cols = ['signal_1', 'sost_1', 'signal_2', 'sost_2', 'sost_mean', 'l1_4', 'left_hip']\n",
                "df.columns = cols\n",
                "\n",
                "print(f\"Data dimensions: {df.shape}\")\n",
                "\n",
                "# Add class labels\n",
                "if len(df) == 103:\n",
                "    df['class'] = ['Health'] * 35 + ['Osteopenia'] * 33 + ['Osteoporosis'] * 35\n",
                "    print(\"103 rows: Health(35) + Osteopenia(33) + Osteoporosis(35)\")\n",
                "else:\n",
                "    df['class'] = ['Health'] * 35 + ['Osteopenia'] * 33 + ['Osteoporosis'] * 36\n",
                "    print(\"104 rows: Health(35) + Osteopenia(33) + Osteoporosis(36)\")\n",
                "\n",
                "print(\"Class distribution:\")\n",
                "print(df['class'].value_counts())\n",
                "\n",
                "# Prepare feature data - only use signal_1 and signal_2\n",
                "X = df[['signal_1', 'signal_2']].values\n",
                "y = df['class'].map({'Health': 0, 'Osteopenia': 1, 'Osteoporosis': 2})\n",
                "\n",
                "print(f\"\\nFeature dimensions: {X.shape}\")\n",
                "print(\"Feature names: Signal1(COL.), Signal2(FL.)\")\n",
                "print(\"Target distribution:\", y.value_counts().sort_index())\n",
                "\n",
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
                "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Color Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n>>> Setting up color scheme...\")\n",
                "\n",
                "# Color configuration\n",
                "COLORS = {\n",
                "    \"green_light\": \"#C9DCC4\",\n",
                "    \"green_transparent\": \"#94C3AA\",\n",
                "    \"blue_light\": \"#D7E8F3\",\n",
                "    \"blue_transparent\": \"#8ec1dc\",\n",
                "    \"teal_transparent\": \"#57B1AB\",\n",
                "    \"new\": \"#DF9D96\"\n",
                "}\n",
                "\n",
                "# Create color maps\n",
                "train_cmap = LinearSegmentedColormap.from_list(\"train_cmap\", [COLORS[\"blue_light\"], COLORS[\"blue_transparent\"]], N=256)\n",
                "test_cmap = LinearSegmentedColormap.from_list(\"test_cmap\", [COLORS[\"green_light\"], COLORS[\"green_transparent\"]], N=256)\n",
                "\n",
                "print(\"✅ Color scheme configured\")\n",
                "\n",
                "# Algorithm configuration\n",
                "algo_configs = {\n",
                "    'SVM': {\n",
                "        'model': SVC(probability=True, random_state=42),\n",
                "        'params': {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']},\n",
                "        'needs_scaling': True,\n",
                "        'color': '#57B1AB'\n",
                "    },\n",
                "    'Random Forest': {\n",
                "        'model': RandomForestClassifier(random_state=42),\n",
                "        'params': {'n_estimators': [50, 100], 'max_depth': [None, 5, 10]},\n",
                "        'needs_scaling': False,\n",
                "        'color': '#94C3AA'\n",
                "    },\n",
                "    'Logistic Regression': {\n",
                "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
                "        'params': {'C': [0.1, 1, 10]},\n",
                "        'needs_scaling': True,\n",
                "        'color': '#8ec1dc'\n",
                "    },\n",
                "    'KNN': {\n",
                "        'model': KNeighborsClassifier(),\n",
                "        'params': {'n_neighbors': [3, 5, 7]},\n",
                "        'needs_scaling': True,\n",
                "        'color': '#DF9D96'\n",
                "    },\n",
                "    'Decision Tree': {\n",
                "        'model': DecisionTreeClassifier(random_state=42),\n",
                "        'params': {'max_depth': [None, 5, 10]},\n",
                "        'needs_scaling': False,\n",
                "        'color': '#C9DCC4'\n",
                "    },\n",
                "    'LDA': {\n",
                "        'model': LinearDiscriminantAnalysis(),\n",
                "        'params': {},\n",
                "        'needs_scaling': False,\n",
                "        'color': '#8ec1dc'\n",
                "    }\n",
                "}\n",
                "\n",
                "print(\"✅ Algorithm configuration complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Confusion Matrix Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(y_true, y_pred, labels, title, cmap, save_path_base=None):\n",
                "    \"\"\"Plot confusion matrix heatmap with enhanced readability\"\"\"\n",
                "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
                "    \n",
                "    plt.figure(figsize=(8, 7))\n",
                "    ax = sns.heatmap(cm, annot=True, fmt='g', cmap=cmap, \n",
                "                     xticklabels=labels, yticklabels=labels, \n",
                "                     cbar=False, annot_kws={\"size\": 28, \"color\": \"black\", \"weight\": \"bold\"}, \n",
                "                     linewidths=1.5, square=True)\n",
                "    \n",
                "    ax.set_title(title, fontsize=18, fontweight='bold', pad=30)\n",
                "    ax.set_xlabel('Predicted', fontsize=18, fontweight='bold', labelpad=20)\n",
                "    ax.set_ylabel('Actual', fontsize=18, fontweight='bold', labelpad=20)\n",
                "    \n",
                "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center', fontsize=16, \n",
                "                       verticalalignment='top')\n",
                "    ax.set_yticklabels(ax.get_yticklabels(), rotation=90, ha='center', fontsize=16,\n",
                "                       verticalalignment='center')\n",
                "    \n",
                "    ax.tick_params(axis='x', pad=15, length=6)\n",
                "    ax.tick_params(axis='y', pad=12, length=6)\n",
                "    \n",
                "    ax.set_aspect('equal', adjustable='box')\n",
                "    plt.subplots_adjust(bottom=0.22, top=0.85, left=0.22, right=0.95)\n",
                "    \n",
                "    if save_path_base:\n",
                "        tiff_path = f\"{save_path_base}.tiff\"\n",
                "        plt.savefig(tiff_path, format='tiff', dpi=300, bbox_inches='tight', \n",
                "                    facecolor='white', pad_inches=0.3)\n",
                "        \n",
                "        pdf_path = f\"{save_path_base}.pdf\"\n",
                "        plt.savefig(pdf_path, format='pdf', bbox_inches='tight', \n",
                "                    facecolor='white', pad_inches=0.3)\n",
                "        \n",
                "        print(f\"  ✅ Saved: {os.path.basename(tiff_path)}, {os.path.basename(pdf_path)}\")\n",
                "        plt.close()\n",
                "        return tiff_path, pdf_path\n",
                "    else:\n",
                "        plt.show()\n",
                "        return None, None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Metrics Computation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_comprehensive_metrics(y_true, y_pred, y_proba=None):\n",
                "    \"\"\"Compute comprehensive evaluation metrics\"\"\"\n",
                "    acc = accuracy_score(y_true, y_pred)\n",
                "    \n",
                "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, \n",
                "                                                                    average=None, zero_division=0)\n",
                "    \n",
                "    prec_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[0]\n",
                "    recall_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[1]\n",
                "    f1_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)[2]\n",
                "    \n",
                "    prec_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[0]\n",
                "    recall_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[1]\n",
                "    f1_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)[2]\n",
                "    \n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "    \n",
                "    auc_score = None\n",
                "    if y_proba is not None:\n",
                "        try:\n",
                "            auc_score = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    return {\n",
                "        'accuracy': acc,\n",
                "        'precision_macro': prec_macro,\n",
                "        'recall_macro': recall_macro,\n",
                "        'f1_macro': f1_macro,\n",
                "        'precision_weighted': prec_weighted,\n",
                "        'recall_weighted': recall_weighted,\n",
                "        'f1_weighted': f1_weighted,\n",
                "        'precision_per_class': precision,\n",
                "        'recall_per_class': recall,\n",
                "        'f1_per_class': f1,\n",
                "        'support_per_class': support,\n",
                "        'confusion_matrix': cm,\n",
                "        'auc_score': auc_score,\n",
                "        'classification_report': classification_report(y_true, y_pred, target_names=['Health', 'Osteopenia', 'Osteoporosis'])\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Algorithm Training Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_algorithm(algo_name, config, X_train, X_test, y_train, y_test):\n",
                "    \"\"\"Train single algorithm and return complete results\"\"\"\n",
                "    print(f\"\\n--- Training {algo_name} ---\")\n",
                "    \n",
                "    # Data standardization\n",
                "    if config['needs_scaling']:\n",
                "        print(f\"  Applying z-score standardization...\")\n",
                "        scaler = StandardScaler()\n",
                "        X_train_scaled = scaler.fit_transform(X_train)\n",
                "        X_test_scaled = scaler.transform(X_test)\n",
                "    else:\n",
                "        X_train_scaled = X_train.copy()\n",
                "        X_test_scaled = X_test.copy()\n",
                "        scaler = None\n",
                "    \n",
                "    # Parameter optimization\n",
                "    model = config['model']\n",
                "    param_grid = config['params']\n",
                "    \n",
                "    if param_grid:\n",
                "        print(f\"  Parameter optimization...\")\n",
                "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
                "        grid_search.fit(X_train_scaled, y_train)\n",
                "        best_model = grid_search.best_estimator_\n",
                "        best_params = grid_search.best_params_\n",
                "        print(f\"  Best parameters: {best_params}\")\n",
                "    else:\n",
                "        best_model = model\n",
                "        best_model.fit(X_train_scaled, y_train)\n",
                "        best_params = \"Default\"\n",
                "        print(\"  Using default parameters\")\n",
                "    \n",
                "    # Predictions\n",
                "    y_train_pred = best_model.predict(X_train_scaled)\n",
                "    y_test_pred = best_model.predict(X_test_scaled)\n",
                "    \n",
                "    # Probability predictions\n",
                "    try:\n",
                "        y_train_proba = best_model.predict_proba(X_train_scaled)\n",
                "        y_test_proba = best_model.predict_proba(X_test_scaled)\n",
                "    except:\n",
                "        y_train_proba = None\n",
                "        y_test_proba = None\n",
                "    \n",
                "    # Performance metrics\n",
                "    train_acc = accuracy_score(y_train, y_train_pred)\n",
                "    test_acc = accuracy_score(y_test, y_test_pred)\n",
                "    \n",
                "    train_metrics = compute_comprehensive_metrics(y_train, y_train_pred, y_train_proba)\n",
                "    test_metrics = compute_comprehensive_metrics(y_test, y_test_pred, y_test_proba)\n",
                "    \n",
                "    # Cross validation\n",
                "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
                "    \n",
                "    print(f\"  Training accuracy: {train_acc:.4f}\")\n",
                "    print(f\"  Test accuracy: {test_acc:.4f}\")\n",
                "    if test_metrics['auc_score']:\n",
                "        print(f\"  Test AUC: {test_metrics['auc_score']:.4f}\")\n",
                "    print(f\"  5-fold CV: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
                "    \n",
                "    return {\n",
                "        'algorithm': algo_name,\n",
                "        'model': best_model,\n",
                "        'scaler': scaler,\n",
                "        'best_params': best_params,\n",
                "        'train_accuracy': train_acc,\n",
                "        'test_accuracy': test_acc,\n",
                "        'train_metrics': train_metrics,\n",
                "        'test_metrics': test_metrics,\n",
                "        'cv_scores': cv_scores,\n",
                "        'cv_mean': cv_scores.mean(),\n",
                "        'cv_std': cv_scores.std(),\n",
                "        'y_train': y_train,\n",
                "        'y_test': y_test,\n",
                "        'y_train_pred': y_train_pred,\n",
                "        'y_test_pred': y_test_pred,\n",
                "        'y_train_proba': y_train_proba,\n",
                "        'y_test_proba': y_test_proba\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train All Algorithms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n>>> Training and evaluating six machine learning algorithms...\")\n",
                "all_results = []\n",
                "class_labels = ['Health', 'Osteopenia', 'Osteoporosis']\n",
                "\n",
                "for algo_name, config in algo_configs.items():\n",
                "    result = train_algorithm(algo_name, config, X_train, X_test, y_train, y_test)\n",
                "    all_results.append(result)\n",
                "\n",
                "print(f\"\\n✅ All algorithms training completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate Confusion Matrix Heatmaps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n>>> Generating confusion matrix heatmaps (TIFF and PDF formats)...\")\n",
                "\n",
                "output_dir = r\"F:\\作图目录20280825\\signal_confusion_matrices\"\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "generated_files = []\n",
                "\n",
                "for result in all_results:\n",
                "    algo_name = result['algorithm']\n",
                "    print(f\"\\nGenerating {algo_name} confusion matrices...\")\n",
                "    \n",
                "    # Training confusion matrix\n",
                "    train_title = f\"Confusion Matrix(Train) - {algo_name}\"\n",
                "    train_path_base = os.path.join(output_dir, f\"{algo_name.replace(' ', '_')}_signal_train\")\n",
                "    tiff_train, pdf_train = plot_confusion_matrix(\n",
                "        result['y_train'], result['y_train_pred'], \n",
                "        class_labels, train_title, train_cmap, train_path_base\n",
                "    )\n",
                "    \n",
                "    # Test confusion matrix\n",
                "    test_title = f\"Confusion Matrix(Test) - {algo_name}\"\n",
                "    test_path_base = os.path.join(output_dir, f\"{algo_name.replace(' ', '_')}_signal_test\")\n",
                "    tiff_test, pdf_test = plot_confusion_matrix(\n",
                "        result['y_test'], result['y_test_pred'], \n",
                "        class_labels, test_title, test_cmap, test_path_base\n",
                "    )\n",
                "    \n",
                "    if tiff_train and pdf_train and tiff_test and pdf_test:\n",
                "        generated_files.extend([tiff_train, pdf_train, tiff_test, pdf_test])\n",
                "\n",
                "print(f\"\\n✅ Generated {len(generated_files)} confusion matrix files\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Performance Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"Signal1+Signal2 Feature Classification Performance Summary\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "performance_data = []\n",
                "for result in all_results:\n",
                "    test_metrics = result['test_metrics']\n",
                "    auc_str = f\"{test_metrics['auc_score']:.4f}\" if test_metrics['auc_score'] else \"N/A\"\n",
                "    performance_data.append({\n",
                "        'Algorithm': result['algorithm'],\n",
                "        'Train Accuracy': f\"{result['train_accuracy']:.4f}\",\n",
                "        'Test Accuracy': f\"{result['test_accuracy']:.4f}\", \n",
                "        'Precision (Macro)': f\"{test_metrics['precision_macro']:.4f}\",\n",
                "        'Recall (Macro)': f\"{test_metrics['recall_macro']:.4f}\",\n",
                "        'F1 Score (Macro)': f\"{test_metrics['f1_macro']:.4f}\",\n",
                "        'AUC Score': auc_str,\n",
                "        'CV Mean': f\"{result['cv_mean']:.4f}\",\n",
                "        'CV Std': f\"{result['cv_std']:.4f}\"\n",
                "    })\n",
                "\n",
                "perf_df = pd.DataFrame(performance_data)\n",
                "print(perf_df.to_string(index=False))\n",
                "\n",
                "print(\"\\n✅ Analysis complete! All confusion matrix heatmaps saved with optimized font sizes\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}